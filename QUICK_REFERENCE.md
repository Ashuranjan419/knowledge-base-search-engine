# âš¡ Quick Reference - Knowledge Base Search Engine

## ğŸš€ Quick Start

```bash
# 1. Install dependencies
cd backend
pip install -r requirements.txt

# 2. Configure API key
cp .env.example .env
# Edit .env and add: OPENAI_API_KEY=your_key_here

# 3. Start server
python main.py

# 4. Open frontend
# Open frontend/index.html in browser
```

## ğŸ“¡ API Endpoints Cheat Sheet

| Method | Endpoint | Description | Example |
|--------|----------|-------------|---------|
| GET | `/` | API info | `curl localhost:8000/` |
| GET | `/health` | Health check | `curl localhost:8000/health` |
| POST | `/upload` | Upload documents | `curl -X POST -F "files=@doc.pdf" localhost:8000/upload` |
| POST | `/query` | Query knowledge base | `curl -X POST -H "Content-Type: application/json" -d '{"query":"What is ML?"}' localhost:8000/query` |
| GET | `/documents` | List documents | `curl localhost:8000/documents` |
| DELETE | `/clear` | Clear all documents | `curl -X DELETE localhost:8000/clear` |
| GET | `/docs` | API documentation | Open `localhost:8000/docs` in browser |

## ğŸ”‘ Environment Variables

```env
# Required
OPENAI_API_KEY=sk-...

# Optional (with defaults)
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
LLM_MODEL=gpt-3.5-turbo
TOP_K_RESULTS=3
CHUNK_SIZE=500
CHUNK_OVERLAP=50
```

## ğŸ“‚ Project Structure

```
unthinkable/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py              # FastAPI app & endpoints
â”‚   â”œâ”€â”€ rag.py               # RAG system (embeddings, FAISS, LLM)
â”‚   â”œâ”€â”€ document_utils.py    # PDF/TXT parsing
â”‚   â”œâ”€â”€ config.py            # Configuration management
â”‚   â”œâ”€â”€ requirements.txt     # Python dependencies
â”‚   â””â”€â”€ test_api.py          # API tests
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ index.html           # Web UI
â”œâ”€â”€ sample_documents/
â”‚   â”œâ”€â”€ machine_learning_basics.txt
â”‚   â””â”€â”€ data_science_intro.txt
â”œâ”€â”€ .env                     # Environment variables (create from .env.example)
â”œâ”€â”€ .env.example             # Environment template
â”œâ”€â”€ .gitignore              # Git ignore rules
â”œâ”€â”€ README.md               # Main documentation
â”œâ”€â”€ SETUP.md                # Detailed setup guide
â”œâ”€â”€ DEMO_GUIDE.md           # Demo instructions
â””â”€â”€ start.bat/start.sh      # Startup scripts
```

## ğŸ› ï¸ Common Commands

```bash
# Activate virtual environment
# Windows:
venv\Scripts\activate
# Mac/Linux:
source venv/bin/activate

# Start backend
cd backend && python main.py

# Run tests
cd backend && python test_api.py

# Serve frontend
cd frontend && python -m http.server 8080

# Install new package
pip install package-name
pip freeze > requirements.txt

# Check logs
# Backend logs print to console
```

## ğŸ§ª Testing

```python
# Using Python
import requests

# Upload
with open('doc.pdf', 'rb') as f:
    r = requests.post('http://localhost:8000/upload', files={'files': f})
print(r.json())

# Query
r = requests.post('http://localhost:8000/query', 
                  json={'query': 'What is ML?', 'top_k': 3})
print(r.json()['answer'])
```

```bash
# Using cURL
# Upload
curl -X POST "http://localhost:8000/upload" -F "files=@document.pdf"

# Query
curl -X POST "http://localhost:8000/query" \
  -H "Content-Type: application/json" \
  -d '{"query": "What is machine learning?", "top_k": 3}'
```

## ğŸ› Troubleshooting Quick Fixes

| Problem | Solution |
|---------|----------|
| Module not found | `pip install -r requirements.txt` |
| Port in use | Change `API_PORT` in `.env` or kill process |
| OpenAI API error | Check API key in `.env`, verify credits |
| PDF parsing fails | Ensure PDF has text (not scanned), not encrypted |
| Frontend not connecting | Check backend running, CORS settings, API_URL |
| Slow performance | Reduce CHUNK_SIZE, TOP_K_RESULTS in `.env` |

## ğŸ’¡ Sample Queries

```
"What is machine learning?"
"Explain supervised learning with examples"
"What are the types of machine learning?"
"What is the difference between supervised and unsupervised learning?"
"What tools do data scientists use?"
"Explain the data science process"
"What are common evaluation metrics for classification?"
"What is deep learning?"
```

## ğŸ¯ Key Features

- âœ… Multi-document upload (PDF, TXT)
- âœ… Semantic search with embeddings
- âœ… RAG-based answer synthesis
- âœ… Source citation with relevance scores
- âœ… REST API with FastAPI
- âœ… Web interface
- âœ… Real-time processing

## ğŸ“Š Performance Metrics

- Document processing: ~100 chunks/second
- Query response: < 2 seconds (with LLM)
- Supported file size: Up to 100MB
- Concurrent queries: Supported

## ğŸ”— Important URLs

- Backend: http://localhost:8000
- Frontend: http://localhost:8080 (or direct file open)
- API Docs: http://localhost:8000/docs
- Health Check: http://localhost:8000/health

## ğŸ“š Core Technologies

| Component | Technology |
|-----------|-----------|
| Backend Framework | FastAPI |
| Embeddings | Sentence Transformers |
| Vector Store | FAISS |
| LLM | OpenAI GPT-3.5/4 |
| PDF Parsing | PyPDF2, pdfplumber |
| Frontend | HTML/CSS/JavaScript |

## ğŸ“ Key Concepts

**RAG (Retrieval-Augmented Generation)**
1. **Retrieval**: Find relevant documents using vector similarity
2. **Augmentation**: Add retrieved context to prompt
3. **Generation**: LLM generates answer based on context

**Pipeline Flow**
```
Document â†’ Chunk â†’ Embed â†’ Store in FAISS
Query â†’ Embed â†’ Search FAISS â†’ Get chunks â†’ LLM â†’ Answer
```

## ğŸ“ Code Snippets

**Add custom preprocessing**
```python
# In document_utils.py
def preprocess_text(text):
    # Add your custom preprocessing
    text = text.lower()
    text = remove_special_chars(text)
    return text
```

**Change embedding model**
```python
# In .env
EMBEDDING_MODEL=sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
```

**Modify LLM prompt**
```python
# In rag.py, synthesize_answer method
prompt = f"""Custom prompt here...
Context: {context}
Question: {query}
Answer:"""
```

## ğŸš€ Deployment Checklist

- [ ] Use environment variables for all secrets
- [ ] Enable HTTPS
- [ ] Add authentication/authorization
- [ ] Implement rate limiting
- [ ] Set up monitoring/logging
- [ ] Configure CORS properly
- [ ] Use production-grade ASGI server (gunicorn + uvicorn)
- [ ] Set up database for persistence (optional)
- [ ] Configure backup for uploaded files
- [ ] Add error tracking (Sentry)

## ğŸ“ Support

- ğŸ“– Documentation: README.md, SETUP.md, DEMO_GUIDE.md
- ğŸ› Issues: [GitHub Issues]
- ğŸ’¬ Questions: [Contact information]

---

**Last Updated**: October 2025
